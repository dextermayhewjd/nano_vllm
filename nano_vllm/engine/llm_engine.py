
"""
"The LLMEngine class is the core component of the vLLM engine. 
It is responsible for receiving requests from clients and generating outputs from the model. 

The LLMEngine includes
    input processing, 
    model execution (possibly distributed across multiple hosts and/or GPUs), 
    scheduling 
    output processing.
    
Input Processing: Handles tokenization of input text using the specified tokenizer.

Scheduling: Chooses which requests are processed in each step.

Model Execution: Manages the execution of the language model, including distributed execution across multiple GPUs.

Output Processing: Processes the outputs generated by the model, decoding the token IDs from a language model into human-readable text.
The code for LLMEngine can be found in vllm/engine/llm_engine.py.

M0阶段目标
nano_vllm/
  __init__.py
  engine.py
  scheduler.py    # 先空着，M1 再写
  worker.py       # 先空着，M2 再写
  types.py
examples/
  simple_generate.py
  
"""